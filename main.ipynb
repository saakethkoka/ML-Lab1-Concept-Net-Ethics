{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "\n",
    "We will be investigating sexual orientation bias in the domain of sentiment anlaysis between different pretrained word embeddings, Stanford's Glove (we will be using the 200 dimensional version trained on Twitter), and the latest version of ConceptNet Numberbatch, word embeddings that take other pretrained embeddings, such as Glove, word2vec, etc. and preturb them using the distance to neighbors in the ConceptNet Knowledge graph. We feel this investigation is pertienet given the ongoing tocxicity of the Internet, twitter in particular, and may show how the choice of embeddings can affect the bias of the model, even if it is trained on the same (probably biased) data. Furthermore, with the rise of complex deep learning based language models in NLP and a shift away from interpreability and methodology, this invesdtigtion may elucidate how biases can also affect the results of relatively sophisticated models. \n",
    "\n",
    "Our research question is: How does the usage of different pretrained word embeddings affect sexual orientation bias in setiment analysis? \n",
    "We hypothesize that the usage of different embeddings will affect the sexual orientation bias of the resulting model to a significant extent. In particular, we believe that the Glove embeddings trained on Twitter will exacerbate the presumable existing biases in the dataset (c'mon, it's twitter) and that the ConceptNet Numberbatch embeddings will hopefully mitigate this bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", encoding=\"ISO-8859-1\", header=None)\n",
    "data = data[[0,5]]\n",
    "data.columns = [\"sentiment\", \"text\"]\n",
    "\n",
    "data[\"sentiment\"] = data[\"sentiment\"].replace(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 594848 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"text\"], data[\"sentiment\"], test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print('Found %s unique tokens.' % (len(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of this code was taken from the last lab of the previous course\n",
    "\n",
    "def load_embeddings(filename, embed_size):\n",
    "    # the embed size should match the file you load glove from\n",
    "    embeddings_index = {}\n",
    "    f = open(filename)\n",
    "    # save key/array pairs of the embeddings\n",
    "    #  the key of the dictionary is the word, the array is the embedding\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "    # now fill in the matrix, using the ordering from the\n",
    "    #  keras word tokenizer from before\n",
    "    found_words = 0\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be ALL-ZEROS\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            found_words = found_words+1\n",
    "\n",
    "    print(\"Embedding Shape:\",embedding_matrix.shape, \"\\n\",\n",
    "        \"Total words found:\",found_words, \"\\n\",\n",
    "        \"Percentage:\",100*found_words/embedding_matrix.shape[0])\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n",
      "Embedding Shape: (594849, 200) \n",
      " Total words found: 121078 \n",
      " Percentage: 20.35440927025178\n"
     ]
    }
   ],
   "source": [
    "glove_embeddings = load_embeddings(\"glove.twitter.27B.200d.txt\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 516783 word vectors.\n",
      "Embedding Shape: (594849, 300) \n",
      " Total words found: 75671 \n",
      " Percentage: 12.721043491709661\n"
     ]
    }
   ],
   "source": [
    "numberbatch_embeddings = load_embeddings(\"numberbatch-en.txt\", 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train_sequences, maxlen=30)\n",
    "X_test = pad_sequences(X_test_sequences, maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ART_LEN = 30\n",
    "\n",
    "# save this embedding now\n",
    "glove_embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            200,\n",
    "                            weights=[glove_embeddings],# here is the embedding getting saved\n",
    "                            input_length=MAX_ART_LEN,\n",
    "                            trainable=False)\n",
    "                            \n",
    "numberbatch_embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            300,\n",
    "                            weights=[numberbatch_embeddings],# here is the embedding getting saved\n",
    "                            input_length=MAX_ART_LEN,\n",
    "                            trainable=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 30, 200)           118969800 \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (None, 30, 128)          135680    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_12 (Bidirecti  (None, 64)               41216     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,146,761\n",
      "Trainable params: 176,961\n",
      "Non-trainable params: 118,969,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "glove_rnn = Sequential()\n",
    "glove_rnn.add(glove_embedding_layer)\n",
    "glove_rnn.add(Bidirectional(LSTM(64, return_sequences=True, dropout=0.2)))\n",
    "glove_rnn.add(Bidirectional(LSTM(32, dropout=0.2)))\n",
    "glove_rnn.add(Dense(1, activation='sigmoid'))\n",
    "glove_rnn.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "glove_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 02:56:18.341296: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 02:56:18.386053: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 02:56:18.386275: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 02:56:18.386938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-08 02:56:18.387855: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 02:56:18.388027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 02:56:18.388172: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 02:56:18.845967: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 02:56:18.846442: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 02:56:18.846544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 02:56:18.846633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5543 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050, pci bus id: 0000:05:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 30, 300)           178454700 \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 30, 128)          186880    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               41216     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 178,682,861\n",
      "Trainable params: 228,161\n",
      "Non-trainable params: 178,454,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "numberbatch_rnn = Sequential()\n",
    "numberbatch_rnn.add(numberbatch_embedding_layer)\n",
    "numberbatch_rnn.add(Bidirectional(LSTM(64, return_sequences=True, dropout=0.2)))\n",
    "numberbatch_rnn.add(Bidirectional(LSTM(32, dropout=0.2)))\n",
    "numberbatch_rnn.add(Dense(1, activation='sigmoid'))\n",
    "numberbatch_rnn.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',       \n",
    "                metrics=['accuracy'])\n",
    "numberbatch_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_callable = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"glove_model.h5\",\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True)\n",
    "\n",
    "numberbatch_callable = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"numberbatch_model.h5\",\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 246s 6ms/step - loss: 0.4180 - accuracy: 0.8063 - val_loss: 0.3852 - val_accuracy: 0.8251\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 244s 6ms/step - loss: 0.3869 - accuracy: 0.8238 - val_loss: 0.3770 - val_accuracy: 0.8301\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 246s 6ms/step - loss: 0.3776 - accuracy: 0.8295 - val_loss: 0.3730 - val_accuracy: 0.8330\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 260s 6ms/step - loss: 0.3729 - accuracy: 0.8322 - val_loss: 0.3699 - val_accuracy: 0.8338\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 258s 6ms/step - loss: 0.3698 - accuracy: 0.8339 - val_loss: 0.3686 - val_accuracy: 0.8349\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 256s 6ms/step - loss: 0.3678 - accuracy: 0.8350 - val_loss: 0.3703 - val_accuracy: 0.8348\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 257s 6ms/step - loss: 0.3661 - accuracy: 0.8356 - val_loss: 0.3675 - val_accuracy: 0.8355\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 258s 6ms/step - loss: 0.3649 - accuracy: 0.8362 - val_loss: 0.3693 - val_accuracy: 0.8346\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 259s 6ms/step - loss: 0.3640 - accuracy: 0.8368 - val_loss: 0.3682 - val_accuracy: 0.8363\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 257s 6ms/step - loss: 0.3635 - accuracy: 0.8371 - val_loss: 0.3682 - val_accuracy: 0.8360\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 257s 6ms/step - loss: 0.3628 - accuracy: 0.8375 - val_loss: 0.3679 - val_accuracy: 0.8362\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 258s 6ms/step - loss: 0.3623 - accuracy: 0.8376 - val_loss: 0.3684 - val_accuracy: 0.8352\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 258s 6ms/step - loss: 0.3620 - accuracy: 0.8378 - val_loss: 0.3668 - val_accuracy: 0.8362\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 268s 7ms/step - loss: 0.3613 - accuracy: 0.8383 - val_loss: 0.3678 - val_accuracy: 0.8356\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 279s 7ms/step - loss: 0.3608 - accuracy: 0.8384 - val_loss: 0.3672 - val_accuracy: 0.8361\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 280s 7ms/step - loss: 0.3607 - accuracy: 0.8384 - val_loss: 0.3676 - val_accuracy: 0.8367\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 280s 7ms/step - loss: 0.3604 - accuracy: 0.8387 - val_loss: 0.3662 - val_accuracy: 0.8367\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 280s 7ms/step - loss: 0.3602 - accuracy: 0.8388 - val_loss: 0.3688 - val_accuracy: 0.8362\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 281s 7ms/step - loss: 0.3598 - accuracy: 0.8389 - val_loss: 0.3667 - val_accuracy: 0.8364\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 281s 7ms/step - loss: 0.3598 - accuracy: 0.8389 - val_loss: 0.3672 - val_accuracy: 0.8374\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 279s 7ms/step - loss: 0.3599 - accuracy: 0.8388 - val_loss: 0.3661 - val_accuracy: 0.8366\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 279s 7ms/step - loss: 0.3594 - accuracy: 0.8395 - val_loss: 0.3679 - val_accuracy: 0.8361\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 281s 7ms/step - loss: 0.3595 - accuracy: 0.8393 - val_loss: 0.3660 - val_accuracy: 0.8369\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 282s 7ms/step - loss: 0.3595 - accuracy: 0.8394 - val_loss: 0.3676 - val_accuracy: 0.8367\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 282s 7ms/step - loss: 0.3591 - accuracy: 0.8394 - val_loss: 0.3666 - val_accuracy: 0.8370\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 282s 7ms/step - loss: 0.3590 - accuracy: 0.8394 - val_loss: 0.3661 - val_accuracy: 0.8370\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 281s 7ms/step - loss: 0.3587 - accuracy: 0.8396 - val_loss: 0.3668 - val_accuracy: 0.8368\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 281s 7ms/step - loss: 0.3590 - accuracy: 0.8396 - val_loss: 0.3674 - val_accuracy: 0.8367\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 282s 7ms/step - loss: 0.3588 - accuracy: 0.8395 - val_loss: 0.3668 - val_accuracy: 0.8369\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 282s 7ms/step - loss: 0.3588 - accuracy: 0.8395 - val_loss: 0.3670 - val_accuracy: 0.8365\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 281s 7ms/step - loss: 0.3587 - accuracy: 0.8398 - val_loss: 0.3668 - val_accuracy: 0.8368\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 281s 7ms/step - loss: 0.3588 - accuracy: 0.8395 - val_loss: 0.3682 - val_accuracy: 0.8368\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 281s 7ms/step - loss: 0.3587 - accuracy: 0.8396 - val_loss: 0.3673 - val_accuracy: 0.8367\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 282s 7ms/step - loss: 0.3582 - accuracy: 0.8400 - val_loss: 0.3669 - val_accuracy: 0.8371\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 280s 7ms/step - loss: 0.3584 - accuracy: 0.8398 - val_loss: 0.3682 - val_accuracy: 0.8365\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 280s 7ms/step - loss: 0.3585 - accuracy: 0.8398 - val_loss: 0.3663 - val_accuracy: 0.8368\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 281s 7ms/step - loss: 0.3582 - accuracy: 0.8396 - val_loss: 0.3681 - val_accuracy: 0.8361\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 282s 7ms/step - loss: 0.3582 - accuracy: 0.8397 - val_loss: 0.3673 - val_accuracy: 0.8368\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 281s 7ms/step - loss: 0.3581 - accuracy: 0.8400 - val_loss: 0.3668 - val_accuracy: 0.8366\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 280s 7ms/step - loss: 0.3584 - accuracy: 0.8397 - val_loss: 0.3681 - val_accuracy: 0.8366\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 281s 7ms/step - loss: 0.3579 - accuracy: 0.8403 - val_loss: 0.3680 - val_accuracy: 0.8369\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 281s 7ms/step - loss: 0.3579 - accuracy: 0.8404 - val_loss: 0.3666 - val_accuracy: 0.8365\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 282s 7ms/step - loss: 0.3579 - accuracy: 0.8401 - val_loss: 0.3672 - val_accuracy: 0.8370\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 281s 7ms/step - loss: 0.3581 - accuracy: 0.8398 - val_loss: 0.3679 - val_accuracy: 0.8361\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 281s 7ms/step - loss: 0.3579 - accuracy: 0.8399 - val_loss: 0.3668 - val_accuracy: 0.8371\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 282s 7ms/step - loss: 0.3579 - accuracy: 0.8400 - val_loss: 0.3669 - val_accuracy: 0.8370\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 282s 7ms/step - loss: 0.3580 - accuracy: 0.8401 - val_loss: 0.3659 - val_accuracy: 0.8369\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 281s 7ms/step - loss: 0.3580 - accuracy: 0.8400 - val_loss: 0.3666 - val_accuracy: 0.8371\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 282s 7ms/step - loss: 0.3578 - accuracy: 0.8401 - val_loss: 0.3669 - val_accuracy: 0.8376\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 281s 7ms/step - loss: 0.3576 - accuracy: 0.8403 - val_loss: 0.3683 - val_accuracy: 0.8365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3f647bb1f0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_rnn.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=[glove_callable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 02:56:45.245801: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-02-08 02:56:46.041933: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-02-08 02:56:46.043317: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f571c7c09a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-08 02:56:46.043336: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3050, Compute Capability 8.6\n",
      "2023-02-08 02:56:46.058335: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-08 02:56:46.159757: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-08 02:56:46.160699: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2023-02-08 02:56:46.160710: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:237] Used ptxas at ptxas\n",
      "2023-02-08 02:56:46.161299: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-02-08 02:56:46.204266: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19/40000 [..............................] - ETA: 4:06 - loss: 0.6857 - accuracy: 0.5543  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 02:56:46.386412: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-08 02:56:46.392164: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-08 02:56:46.415271: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 283s 7ms/step - loss: 0.4251 - accuracy: 0.8026 - val_loss: 0.3955 - val_accuracy: 0.8193\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 282s 7ms/step - loss: 0.3872 - accuracy: 0.8244 - val_loss: 0.3744 - val_accuracy: 0.8307\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 283s 7ms/step - loss: 0.3736 - accuracy: 0.8317 - val_loss: 0.3689 - val_accuracy: 0.8340\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3648 - accuracy: 0.8367 - val_loss: 0.3660 - val_accuracy: 0.8363\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 286s 7ms/step - loss: 0.3588 - accuracy: 0.8398 - val_loss: 0.3637 - val_accuracy: 0.8380\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 286s 7ms/step - loss: 0.3539 - accuracy: 0.8422 - val_loss: 0.3617 - val_accuracy: 0.8387\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3499 - accuracy: 0.8443 - val_loss: 0.3603 - val_accuracy: 0.8388\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 286s 7ms/step - loss: 0.3469 - accuracy: 0.8462 - val_loss: 0.3611 - val_accuracy: 0.8393\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 286s 7ms/step - loss: 0.3442 - accuracy: 0.8475 - val_loss: 0.3606 - val_accuracy: 0.8401\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3423 - accuracy: 0.8484 - val_loss: 0.3593 - val_accuracy: 0.8400\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 287s 7ms/step - loss: 0.3404 - accuracy: 0.8491 - val_loss: 0.3591 - val_accuracy: 0.8403\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3388 - accuracy: 0.8504 - val_loss: 0.3605 - val_accuracy: 0.8400\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3374 - accuracy: 0.8509 - val_loss: 0.3613 - val_accuracy: 0.8396\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 286s 7ms/step - loss: 0.3361 - accuracy: 0.8515 - val_loss: 0.3628 - val_accuracy: 0.8404\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 286s 7ms/step - loss: 0.3352 - accuracy: 0.8520 - val_loss: 0.3623 - val_accuracy: 0.8399\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 286s 7ms/step - loss: 0.3339 - accuracy: 0.8528 - val_loss: 0.3611 - val_accuracy: 0.8400\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3333 - accuracy: 0.8531 - val_loss: 0.3612 - val_accuracy: 0.8395\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3322 - accuracy: 0.8536 - val_loss: 0.3629 - val_accuracy: 0.8391\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 287s 7ms/step - loss: 0.3315 - accuracy: 0.8539 - val_loss: 0.3621 - val_accuracy: 0.8405\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3309 - accuracy: 0.8541 - val_loss: 0.3613 - val_accuracy: 0.8402\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3300 - accuracy: 0.8546 - val_loss: 0.3637 - val_accuracy: 0.8400\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3297 - accuracy: 0.8548 - val_loss: 0.3643 - val_accuracy: 0.8399\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 286s 7ms/step - loss: 0.3287 - accuracy: 0.8553 - val_loss: 0.3629 - val_accuracy: 0.8396\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3286 - accuracy: 0.8555 - val_loss: 0.3639 - val_accuracy: 0.8401\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3282 - accuracy: 0.8556 - val_loss: 0.3635 - val_accuracy: 0.8399\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3272 - accuracy: 0.8563 - val_loss: 0.3643 - val_accuracy: 0.8393\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 286s 7ms/step - loss: 0.3273 - accuracy: 0.8559 - val_loss: 0.3623 - val_accuracy: 0.8400\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3269 - accuracy: 0.8562 - val_loss: 0.3649 - val_accuracy: 0.8398\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 284s 7ms/step - loss: 0.3266 - accuracy: 0.8562 - val_loss: 0.3628 - val_accuracy: 0.8398\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3263 - accuracy: 0.8565 - val_loss: 0.3627 - val_accuracy: 0.8401\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3259 - accuracy: 0.8570 - val_loss: 0.3626 - val_accuracy: 0.8405\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 284s 7ms/step - loss: 0.3258 - accuracy: 0.8568 - val_loss: 0.3629 - val_accuracy: 0.8400\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 286s 7ms/step - loss: 0.3253 - accuracy: 0.8571 - val_loss: 0.3649 - val_accuracy: 0.8405\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3249 - accuracy: 0.8571 - val_loss: 0.3646 - val_accuracy: 0.8403\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 286s 7ms/step - loss: 0.3247 - accuracy: 0.8574 - val_loss: 0.3641 - val_accuracy: 0.8401\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 286s 7ms/step - loss: 0.3249 - accuracy: 0.8575 - val_loss: 0.3647 - val_accuracy: 0.8391\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 286s 7ms/step - loss: 0.3245 - accuracy: 0.8576 - val_loss: 0.3623 - val_accuracy: 0.8401\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3240 - accuracy: 0.8577 - val_loss: 0.3639 - val_accuracy: 0.8401\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3237 - accuracy: 0.8576 - val_loss: 0.3642 - val_accuracy: 0.8398\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 286s 7ms/step - loss: 0.3236 - accuracy: 0.8579 - val_loss: 0.3657 - val_accuracy: 0.8395\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 286s 7ms/step - loss: 0.3236 - accuracy: 0.8575 - val_loss: 0.3640 - val_accuracy: 0.8398\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3232 - accuracy: 0.8578 - val_loss: 0.3636 - val_accuracy: 0.8396\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 280s 7ms/step - loss: 0.3231 - accuracy: 0.8582 - val_loss: 0.3650 - val_accuracy: 0.8403\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 264s 7ms/step - loss: 0.3229 - accuracy: 0.8582 - val_loss: 0.3641 - val_accuracy: 0.8397\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 277s 7ms/step - loss: 0.3225 - accuracy: 0.8583 - val_loss: 0.3648 - val_accuracy: 0.8400\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 283s 7ms/step - loss: 0.3225 - accuracy: 0.8581 - val_loss: 0.3659 - val_accuracy: 0.8402\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 284s 7ms/step - loss: 0.3219 - accuracy: 0.8590 - val_loss: 0.3666 - val_accuracy: 0.8399\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 284s 7ms/step - loss: 0.3222 - accuracy: 0.8589 - val_loss: 0.3637 - val_accuracy: 0.8400\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 285s 7ms/step - loss: 0.3219 - accuracy: 0.8587 - val_loss: 0.3638 - val_accuracy: 0.8396\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 284s 7ms/step - loss: 0.3219 - accuracy: 0.8587 - val_loss: 0.3645 - val_accuracy: 0.8394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b1b74eaf0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberbatch_rnn.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=[numberbatch_callable])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the trained models from disk: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_rnn = keras.models.load_model(\"glove_model.h5\")\n",
    "numberbatch_rnn = keras.models.load_model(\"numberbatch_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uReturns sentiment of a sentence derived from the model\n",
    "def get_sentiment(sentence, model):\n",
    "    sentence = tokenizer.texts_to_sequences(sentence)\n",
    "    sentence = pad_sequences(sentence, maxlen=30)\n",
    "    # print model weights:\n",
    "    return model.predict(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in CommonNames.csv\n",
    "names = pd.read_csv(\"CommonNames.csv\")\n",
    "male_names = names[\"Male\"][:20] # Top 20 male names of the 2000s\n",
    "female_names = names[\"Female\"][:20] # Top 20 female names of the 2000s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of sentences with formatting\n",
    "lgbtq_sentence_templates = [\n",
    "    \"{} is a .\",\n",
    "]\n",
    "\n",
    "straight_sentence_templates = [\n",
    "    \"{} is straight.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbtq_sentences = []\n",
    "straight_sentences = []\n",
    "\n",
    "for sentence in lgbtq_sentence_templates:\n",
    "    for name in male_names:\n",
    "        curr_sentence = sentence.format(name)\n",
    "        lgbtq_sentences.append(sentence.format(name))\n",
    "    for name in female_names:\n",
    "        lgbtq_sentences.append(sentence.format(name))\n",
    "\n",
    "for sentence in straight_sentence_templates:\n",
    "    for name in male_names:\n",
    "        straight_sentences.append(sentence.format(name))\n",
    "    for name in female_names:\n",
    "        straight_sentences.append(sentence.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8558687"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment(lgbtq_sentences, glove_rnn).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7447921"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment(straight_sentences, glove_rnn).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95314467"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment(lgbtq_sentences, numberbatch_rnn).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6283485"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment(straight_sentences, numberbatch_rnn).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
